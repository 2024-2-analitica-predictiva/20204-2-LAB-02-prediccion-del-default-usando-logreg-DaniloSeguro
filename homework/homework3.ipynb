{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Cargar datos de entrenamiento\n",
    "import pandas as pd  #  type: ignore\n",
    "\n",
    "train_data = pd.read_csv(\n",
    "    \"../files/input/train_data.csv.zip\",\n",
    "    #index_col=False,\n",
    "    compression=\"zip\",\n",
    ")\n",
    "\n",
    "\n",
    "#  Cargar datos de prueba\n",
    "import pandas as pd  #  type: ignore\n",
    "\n",
    "test_data = pd.read_csv(\n",
    "    \"../files/input/test_data.csv.zip\",\n",
    "    #index_col=False,\n",
    "    compression=\"zip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\AppData\\Local\\Temp\\ipykernel_32112\\3232869872.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[test_data[\"EDUCATION\"] > 4, \"EDUCATION\"] = 4\n",
      "C:\\Users\\danil\\AppData\\Local\\Temp\\ipykernel_32112\\3232869872.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[train_data[\"EDUCATION\"] > 4, \"EDUCATION\"] = 4\n"
     ]
    }
   ],
   "source": [
    "# Paso 1.\n",
    "# Realice la limpieza de los datasets:\n",
    "# - Renombre la columna \"default payment next month\" a \"default\".\n",
    "# - Remueva la columna \"ID\".\n",
    "# - Elimine los registros con informacion no disponible.\n",
    "# - Para la columna EDUCATION, valores > 4 indican niveles superiores\n",
    "#   de educación, agrupe estos valores en la categoría \"others\".\n",
    "#\n",
    "# Renombre la columna \"default payment next month\" a \"default\"\n",
    "# y remueva la columna \"ID\".\n",
    "\n",
    "# - Renombre la columna \"default payment next month\" a \"default\".\n",
    "train_data.rename(columns={'default payment next month': 'default'}, inplace=True)\n",
    "test_data.rename(columns={'default payment next month': 'default'}, inplace=True)\n",
    "\n",
    "#  Eliminar la columna ID\n",
    "train_data.drop(columns=['ID'], inplace=True)\n",
    "test_data.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "# Elimine los registros con informacion no disponible.\n",
    "test_data.dropna(inplace=True)\n",
    "test_data.isna().sum()\n",
    "\n",
    "# Para la columna EDUCATION, valores > 4 indican niveles superiores, \n",
    "# agrupe estos valores en la categoría \"others\", es decir igual a 4\n",
    "# train_data['EDUCATION'] = train_data['EDUCATION'].apply(lambda x: x if x <= 4 else 4)\n",
    "# test_data['EDUCATION'] = test_data['EDUCATION'].apply(lambda x: x if x <= 4 else 4)\n",
    "\n",
    "\n",
    "df = test_data.loc[(test_data[\"EDUCATION\"] != 0)]\n",
    "df = test_data.loc[(test_data[\"MARRIAGE\"] != 0)]\n",
    "df.loc[test_data[\"EDUCATION\"] > 4, \"EDUCATION\"] = 4\n",
    "\n",
    "df = train_data.loc[(train_data[\"EDUCATION\"] != 0)]\n",
    "df = train_data.loc[(train_data[\"MARRIAGE\"] != 0)]\n",
    "df.loc[train_data[\"EDUCATION\"] > 4, \"EDUCATION\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2.\n",
    "# Divida los datasets en x_train, y_train, x_test, y_test.\n",
    "# Divida los datasets en x_train, y_train, x_test, y_test\n",
    "# x_train y x_test contienen  todas las columnas excepto la columna default.\n",
    "# y_train y y_test contiene la variable objetivo default (pago)\n",
    "x_train = train_data.drop(['default'], axis=1)\n",
    "y_train = train_data['default']\n",
    "\n",
    "x_test = test_data.drop(['default'], axis=1)\n",
    "y_test = test_data['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado. Precisión en test: 0.8205555555555556\n"
     ]
    }
   ],
   "source": [
    "# Paso 3.\n",
    "# Cree un pipeline para el modelo de clasificación. Este pipeline debe\n",
    "# contener las siguientes capas:\n",
    "# - Transforma las variables categoricas usando el método\n",
    "#   one-hot-encoding.\n",
    "# - Escala las demas variables al intervalo [0, 1].\n",
    "# - Selecciona las K mejores caracteristicas.\n",
    "# - Ajusta un modelo de regresion logistica.\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Definir columnas categóricas y numéricas\n",
    "categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "numerical_features = ['LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "                   'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "                   'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "\n",
    "# Preprocesamiento para las variables categóricas\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "# Preprocesamiento para las variables numéricas\n",
    "numerical_transformer = MinMaxScaler()\n",
    "\n",
    "# Combinación de preprocesadores\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"encoder\", categorical_transformer, categorical_features),\n",
    "        (\"numerica\", numerical_transformer, numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Creación del Pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"selectkbest\", SelectKBest(score_func=f_regression, k=10)),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Ajustar el pipeline con los datos de entrenamiento\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "print(\"Modelo entrenado. Precisión en test:\", pipeline.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros:  {'classifier__C': 1, 'classifier__solver': 'liblinear', 'selectkbest__k': 1}\n",
      "Balanced Accuracy en el conjunto de entrenamiento: 0.6391959574465568\n",
      "Balanced Accuracy en el conjunto de prueba: 0.654602898974264\n"
     ]
    }
   ],
   "source": [
    "# Paso 4.\n",
    "# Optimice los hiperparametros del pipeline usando validación cruzada.\n",
    "# Use 10 splits para la validación cruzada. Use la función de precision\n",
    "# balanceada para medir la precisión del modelo.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Definición del grid de hiperparámetros\n",
    "param_grid = {\n",
    "    #\"feature_selection__k\": range(1, 10),  # Diferentes valores de k para probar\n",
    "    \"selectkbest__k\": range(1, len(x_train.columns) + 1),  # Diferentes valores de k para probar\n",
    "    \"classifier__C\": [0.1, 1, 10],  # 1 poner rango de valores\n",
    "    \"classifier__solver\": [\"liblinear\", \"lbfgs\"]\n",
    "    #\"classifier__solver\": [\"liblinear\"],  # Solvers disponibles  \"saga\" para l1 y l2, \"lbfgs\" para l2, \"liblinear\" l1\n",
    "    #\"classifier__penalty\": [\"l1\"],  # Penalización l1 o l2\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Validación cruzada con 10 splits\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring=\"balanced_accuracy\", n_jobs=-1, refit=True )\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Mejor modelo\n",
    "print(\"Mejores parámetros: \", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluación en el conjunto de entrenamiento\n",
    "y_train_pred = best_model.predict(x_train)  # Predicciones en el conjunto de entrenamiento\n",
    "balanced_acc_train = balanced_accuracy_score(y_train, y_train_pred)  # Comparar con las etiquetas verdaderas de entrenamiento\n",
    "print(\"Balanced Accuracy en el conjunto de entrenamiento:\", balanced_acc_train)\n",
    "\n",
    "# Evaluación en el conjunto de test\n",
    "y_test_pred = best_model.predict(x_test)  # Predicciones en el conjunto de test\n",
    "balanced_acc_test = balanced_accuracy_score(y_test, y_test_pred)  # Comparar con las etiquetas verdaderas de test\n",
    "print(\"Balanced Accuracy en el conjunto de prueba:\", balanced_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5.\n",
    "# Guarde el modelo (comprimido con gzip) como \"files/models/model.pkl.gz\".\n",
    "# Recuerde que es posible guardar el modelo comprimido usanzo la libreria gzip.\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# Guardar el modelo comprimido con gzip\n",
    "with gzip.open('../files/models/model.pkl.gz', 'wb') as file:\n",
    "    pickle.dump(grid_search, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train': {'Accuracy': 0.815, 'Balanced accuracy': np.float64(0.6391959574465568), 'Precision': 0.6932966023875115, 'Recall': 0.31944150624074463, 'F1-Score': 0.4373642288196959}, 'Test': {'Accuracy': 0.8303333333333334, 'Balanced accuracy': np.float64(0.654602898974264), 'Precision': 0.7006302521008403, 'Recall': 0.3493975903614458, 'F1-Score': 0.46627053477804964}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, balanced_accuracy_score, f1_score, accuracy_score, precision_score\n",
    "\n",
    "# Predicciones\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "y_test_pred = best_model.predict(x_test)\n",
    "\n",
    "\n",
    "# Métricas\n",
    "metrics = {\n",
    "    \"Train\": {\n",
    "        \"Accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "        \"Balanced accuracy\": balanced_accuracy_score(y_train, y_train_pred),\n",
    "        \"Precision\": precision_score(y_train, y_train_pred),\n",
    "        \"Recall\": recall_score(y_train, y_train_pred),\n",
    "        \"F1-Score\": f1_score(y_train, y_train_pred)\n",
    "    },\n",
    "    \"Test\":{\n",
    "        \"Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"Balanced accuracy\": balanced_accuracy_score(y_test, y_test_pred),\n",
    "        \"Precision\": precision_score(y_test, y_test_pred),\n",
    "        \"Recall\": recall_score(y_test, y_test_pred),\n",
    "        \"F1-Score\": f1_score(y_test, y_test_pred)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'metrics', 'dataset': 'train', 'precision': 0.6932966023875115, 'balanced_accuracy': np.float64(0.6391959574465568), 'recall': 0.31944150624074463, 'f1_score': 0.4373642288196959}, {'type': 'metrics', 'dataset': 'test', 'precision': 0.7006302521008403, 'balanced_accuracy': np.float64(0.654602898974264), 'recall': 0.3493975903614458, 'f1_score': 0.46627053477804964}]\n",
      "{'type': 'cm_matrix', 'dataset': 'train', 'true_0': {'predicted_0': 15605, 'predicted_1': 668}, 'true_1': {'predicted_0': 3217, 'predicted_1': 1510}}\n",
      "{'type': 'cm_matrix', 'dataset': 'test', 'true_0': {'predicted_0': 6806, 'predicted_1': 285}, 'true_1': {'predicted_0': 1242, 'predicted_1': 667}}\n",
      "[{'type': 'metrics', 'dataset': 'train', 'precision': 0.6932966023875115, 'balanced_accuracy': np.float64(0.6391959574465568), 'recall': 0.31944150624074463, 'f1_score': 0.4373642288196959}, {'type': 'metrics', 'dataset': 'test', 'precision': 0.7006302521008403, 'balanced_accuracy': np.float64(0.654602898974264), 'recall': 0.3493975903614458, 'f1_score': 0.46627053477804964}, {'type': 'cm_matrix', 'dataset': 'train', 'true_0': {'predicted_0': 15605, 'predicted_1': 668}, 'true_1': {'predicted_0': 3217, 'predicted_1': 1510}}, {'type': 'cm_matrix', 'dataset': 'test', 'true_0': {'predicted_0': 6806, 'predicted_1': 285}, 'true_1': {'predicted_0': 1242, 'predicted_1': 667}}]\n"
     ]
    }
   ],
   "source": [
    "# Paso 6.\n",
    "# Calcule las metricas de precision, precision balanceada, recall,\n",
    "# y f1-score para los conjuntos de entrenamiento y prueba.\n",
    "# Guardelas en el archivo files/output/metrics.json. Cada fila\n",
    "# del archivo es un diccionario con las metricas de un modelo.\n",
    "# Este diccionario tiene un campo para indicar si es el conjunto\n",
    "# de entrenamiento o prueba. Por ejemplo:\n",
    "#\n",
    "# {'type': 'metrics', 'dataset': 'train', 'precision': 0.8, 'balanced_accuracy': 0.7, 'recall': 0.9, 'f1_score': 0.85}\n",
    "# {'type': 'metrics', 'dataset': 'test', 'precision': 0.7, 'balanced_accuracy': 0.6, 'recall': 0.8, 'f1_score': 0.75}\n",
    "#\n",
    "#\n",
    "# Paso 7.\n",
    "# Calcule las matrices de confusion para los conjuntos de entrenamiento y\n",
    "# prueba. Guardelas en el archivo files/output/metrics.json. Cada fila\n",
    "# del archivo es un diccionario con las metricas de un modelo.\n",
    "# de entrenamiento o prueba. Por ejemplo:\n",
    "#\n",
    "# {'type': 'cm_matrix', 'dataset': 'train', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 666}, 'true_1': {\"predicted_0\": 3333, \"predicted_1\": 1444}}\n",
    "# {'type': 'cm_matrix', 'dataset': 'test', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 650}, 'true_1': {\"predicted_0\": 2490, \"predicted_1\": 1420}}\n",
    "#\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, confusion_matrix\n",
    "import json\n",
    "\n",
    "# Función para calcular las métricas de precisión, recall, etc.\n",
    "def compute_metrics(model, X, y, dataset):\n",
    "    y_pred = model.predict(X)\n",
    "    metrics = classification_report(y, y_pred, output_dict=True)\n",
    "    \n",
    "    # formato de json\n",
    "    results = {\n",
    "        'type': 'metrics',\n",
    "        'dataset': dataset,\n",
    "        'precision': metrics['1']['precision'],\n",
    "        'balanced_accuracy': balanced_accuracy_score(y, y_pred),\n",
    "        'recall': metrics['1']['recall'],\n",
    "        'f1_score': metrics['1']['f1-score']\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# Función para calcular la matriz de confusión\n",
    "def compute_confusion_matrix(model, X, y, dataset):\n",
    "    cm = confusion_matrix(y, model.predict(X))\n",
    "\n",
    "    # formato de json\n",
    "    return {\n",
    "        'type': 'cm_matrix',\n",
    "        'dataset': dataset,\n",
    "        'true_0': {'predicted_0': int(cm[0][0]), 'predicted_1': int(cm[0][1])},\n",
    "        'true_1': {'predicted_0': int(cm[1][0]), 'predicted_1': int(cm[1][1])}\n",
    "    }\n",
    "\n",
    "# Calcula las métricas para entrenamiento y prueba\n",
    "metrics_list = [\n",
    "    compute_metrics(grid_search.best_estimator_, x_train, y_train, 'train'),\n",
    "    compute_metrics(grid_search.best_estimator_, x_test, y_test, 'test')\n",
    "]\n",
    "\n",
    "# Calcula la matriz de confusión para entrenamiento y prueba\n",
    "cm_train = compute_confusion_matrix(grid_search.best_estimator_, x_train, y_train, 'train')\n",
    "cm_test = compute_confusion_matrix(grid_search.best_estimator_, x_test, y_test, 'test')\n",
    "\n",
    "# Crear una lista con todas las métricas y matrices\n",
    "all_results = metrics_list + [cm_train, cm_test]\n",
    "\n",
    "# Guardar todas las métricas y matrices en el archivo 'metrics.json'\n",
    "with open('../files/output/metrics.json', 'w') as file:\n",
    "    for result in all_results:\n",
    "        file.write(json.dumps(result) + '\\n')\n",
    "\n",
    "#mostrar resultados\n",
    "\n",
    "print(metrics_list)\n",
    "print(cm_train)\n",
    "print(cm_test)\n",
    "print(all_results)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
